{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10130440,"sourceType":"datasetVersion","datasetId":6252001}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers trl huggingface_hub\n!pip install rouge-score\n!pip install --upgrade nltk\nimport nltk\nnltk.download('wordnet')\nnltk.download('omw-1.4')\n# Tokenization için NLTK veri indirme\nnltk.download('punkt')\nnltk.download('punkt_tab')\n!pip install bert-score\n!pip install inflect\n!pip install -U bitsandbytes accelerate\n!pip install gspread oauth2client\n\nimport gc\nimport torch\n\nimport transformers\nfrom transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\nimport os\nimport re\nimport inflect\nfrom rouge_score import rouge_scorer\nfrom nltk.translate.meteor_score import single_meteor_score\nfrom bert_score import score as bert_score\nimport pandas as pd\nimport numpy as np\nimport pickle\nimport gspread\nfrom oauth2client.service_account import ServiceAccountCredentials\npd.set_option('display.max_colwidth', None)","metadata":{"id":"Q_7r-xNL8GOr"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_parquet(\"hf://datasets/Muadil/all_unique_cleaned_openai_summarize_comparisons_test/data/train-00000-of-00001.parquet\")","metadata":{"id":"HxaiSARhDBTM"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def initialize_google_sheets():\n    # Google Sheets API'ye erişim için gerekli izinleri ayarlıyoruz\n    client = gspread.service_account(filename=\"/kaggle/input/service-account/august-oarlock-441317-t9-0a0e6dbc7072.json\")\n\n    # Google Sheet'i açıyoruz\n    spreadsheet = client.open_by_url(\n        'https://docs.google.com/spreadsheets/d/1E8xzMYGsCR7M9xCA2pDsfB6MhZIa6M9ZK05TUBW9iGk/edit?usp=sharing')\n\n    # İlk sayfayı alıyoruz\n    return spreadsheet.get_worksheet(0)\n\n\ndef sheets_to_df(worksheet):\n    # Veriyi çekiyoruz ve pandas DataFrame'e çeviriyoruz\n    data = worksheet.get_all_records()  # Bu, veriyi bir liste olarak alır\n    df = pd.DataFrame(data)  # Veriyi DataFrame'e çeviriyoruz\n    return df\n\n\n","metadata":{"id":"e3w7wa0YDFB_"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def write_to_google_sheets(prompts, chosens, predictions, model_name):\n#     \"\"\"\n#     Google Sheets'e verilen verileri yazar ve modelin sütun indeksini otomatik belirler.\n\n#     Args:\n#         prompts (list): Prompt verileri.\n#         chosens (list): Chosen verileri.\n#         predictions (list): Prediction verileri.\n#         model_name (str): Model adı (ilk satıra yazılır ve sütun indeksini belirler).\n#     \"\"\"\n#     model_name = model_name.replace(\"-\", \"_\").replace(\"/\", \"_\")\n\n#     sheet_df = sheets_to_df()\n#     columns = sheet_df.columns.tolist()\n\n#     # Eksik sütunları ekle\n#     for col in [\"Info\", \"Chosen\", \"Score_1\"]:\n#         if col not in columns:\n#             sheet_df[col] = None\n\n#     # Yeni model sütununu ekle\n#     if model_name not in columns:\n#         print(model_name + \"column initialized\")\n#         sheet_df[model_name] = None\n#         # Model ile ilişkili skor sütununu ekle\n#         model_index = sheet_df.columns.get_loc(model_name)\n#         score_col = f\"Score_{model_index}\"\n#         sheet_df[score_col] = None\n\n#     # Satır satır ekleme işlemi\n#     for row_index, (prompt, chosen, prediction) in enumerate(zip(prompts, chosens, predictions), start=0):\n#         # Eğer satır yoksa yeni bir satır ekle\n#         if row_index >= len(sheet_df[model_name]):\n#             sheet_df = pd.concat([sheet_df, pd.DataFrame([{col: None for col in sheet_df.columns}])], ignore_index=True)\n\n#         # Satırdaki değerleri kontrol et ve ekle\n#         if sheet_df.loc[row_index, \"Info\"] in [np.nan, None, \"\"]:\n#             sheet_df.loc[row_index, \"Info\"] = prompt\n\n#         if sheet_df.loc[row_index, \"Chosen\"] in [np.nan, None, \"\"]:\n#             sheet_df.loc[row_index, \"Chosen\"] = chosen\n\n#         if sheet_df.loc[row_index, model_name] in [np.nan, None, \"\"]:\n#             sheet_df.loc[row_index, model_name] = prediction\n#         # if pd.isna(sheet_df.loc[row_index, model_name]):\n#         #     sheet_df.loc[row_index, model_name] = prediction\n\n\n\n\n#     # Boş veya geçersiz verileri temizle\n#     sheet_df = sheet_df.replace([float(\"nan\"), float(\"inf\"), float(\"-inf\")], None)\n\n#     # Google Sheets'e yaz\n#     headers = sheet_df.columns.tolist()\n#     updated_data = sheet_df.values.tolist()\n\n#     worksheet = initialize_google_sheets()\n#     worksheet.clear()\n#     worksheet.append_row(headers)\n#     worksheet.append_rows(updated_data)\n#     print(\"Veri başarıyla güncellendi.\")","metadata":{"id":"CYAOx6ytOWOt"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_data_to_the_sheet(worksheet, sheet_df):\n  # Boş veya geçersiz verileri temizle\n  sheet_df = sheet_df.replace([float(\"nan\"), float(\"inf\"), float(\"-inf\")], None)\n\n  # Google Sheets'e yaz\n  headers = sheet_df.columns.tolist()\n  updated_data = sheet_df.values.tolist()\n\n  worksheet.clear()\n  worksheet.append_row(headers)\n  worksheet.append_rows(updated_data)\n  print(\"Veri başarıyla güncellendi.\")\n\ndef save_the_output(sheet_df, model_name, prediction, row_index):\n    \n\n    model_name = model_name.replace(\"-\", \"_\").replace(\"/\", \"_\")\n    # Yeni model sütununu ekle\n    columns = sheet_df.columns.tolist()\n    if model_name not in columns:\n        print(model_name + \"column initialized\")\n        sheet_df[model_name] = None\n        # Model ile ilişkili skor sütununu ekle\n        size = len(sheet_df.columns.to_list())\n        score_col = f\"Score_{(size-2)/2}\"\n        sheet_df[score_col] = None\n    if sheet_df.loc[row_index, model_name] in [np.nan, None, \"\"]:\n      sheet_df.loc[row_index, model_name] = prediction\n\ndef get_inference(model, tokenizer, text, max_token_length, model_name, device):\n  text = f\"System: I want you to summarize this text\\nDocument: {text}\\nSummary:\"\n  inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_token_length).to(device)\n  output = model.generate(**inputs, max_new_tokens=max_token_length, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)\n  prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n  if \"instruct\" in model_name.lower():\n    if \"Summary:\" in prediction:\n        prediction = prediction.split(\"Summary:\")[1].strip()\n    else:\n        prediction = prediction  # Beklenmeyen durumlar için\n\n  return prediction","metadata":{"id":"v3idaEBcOXm-"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_summary_metrics(references, predictions):\n    \"\"\"\n    Büyük dil modellerinde başarı metriklerini hesaplamak için fonksiyon.\n\n    Args:\n        references (list): Gerçek özetlerin listesi.\n        predictions (list): Model tarafından üretilen özetlerin listesi.\n\n    Returns:\n        dict: Ortalama ROUGE, METEOR, BERTScore ve MoverScore metriklerini içeren bir sözlük.\n    \"\"\"\n    if len(references) != len(predictions):\n        raise ValueError(\"References ve predictions aynı uzunlukta olmalı!\")\n\n    # ROUGE skorları için scorer tanımlanıyor\n    rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    rouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n    meteor_scores = []\n\n    # ROUGE ve METEOR hesaplamaları\n    for ref, pred in zip(references, predictions):\n        # ROUGE skorları\n        rouge_scores = rouge_scorer_obj.score(ref, pred)\n        rouge1_scores.append(rouge_scores['rouge1'].fmeasure)\n        rouge2_scores.append(rouge_scores['rouge2'].fmeasure)\n        rougeL_scores.append(rouge_scores['rougeL'].fmeasure)\n\n        # METEOR skoru (cümleleri tokenize ediyoruz)\n        tokenized_ref = nltk.word_tokenize(ref)\n        tokenized_pred = nltk.word_tokenize(pred)\n        meteor_scores.append(single_meteor_score(tokenized_ref, tokenized_pred))\n\n    # BERTScore hesaplaması\n    P, R, F1 = bert_score(predictions, references, lang=\"en\", rescale_with_baseline=True)\n    bert_f1 = F1.mean().item()\n\n    # MoverScore hesaplaması\n    #moverscores = get_moverscore(references, predictions)\n\n    # Ortalama skorlar\n    scores = {\n        'ROUGE-1': sum(rouge1_scores) / len(rouge1_scores),\n        'ROUGE-2': sum(rouge2_scores) / len(rouge2_scores),\n        'ROUGE-L': sum(rougeL_scores) / len(rougeL_scores),\n        'METEOR': sum(meteor_scores) / len(meteor_scores),\n        'BERTScore': bert_f1,\n        #'MoverScore': sum(moverscores) / len(moverscores)\n    }\n\n    return scores\n\ndef add_metrics_to_dataframe(metrics_df, model_name, references, predictions):\n    \"\"\"\n    Başarı metriklerini hesaplayarak verilen DataFrame'e ekler.\n\n    Args:\n        metrics_df (pd.DataFrame): Başarı metriklerini saklayan mevcut DataFrame.\n        model_name (str): Modelin adı.\n        references (list): Gerçek özetlerin listesi.\n        predictions (list): Model tarafından üretilen özetlerin listesi.\n\n    Returns:\n        pd.DataFrame: Güncellenmiş metrikler tablosu.\n    \"\"\"\n    # Metrikleri hesapla\n    scores = calculate_summary_metrics(references, predictions)\n\n    # Yeni bir satır olarak metrikleri eklemek için model adını ekle\n    scores[\"Model Name\"] = model_name\n    metrics_df = pd.concat([metrics_df, pd.DataFrame([scores])], ignore_index=True)\n\n    return metrics_df\n\n\n\n\ndef summarize_and_save_metrics_AutoModelForSeq2SeqLM(models, tokenizer_names, texts, references, metrics_df=None, device=\"cpu\", max_token_length = 2048):\n    \"\"\"\n    Modellerle özetleme yapar, başarı metriklerini hesaplar ve DataFrame'e kaydeder.\n\n    Args:\n        models (list): Özetleme yapacak model isimlerinin listesi.\n        tokenizer_names (list): Model isimlerine karşılık gelen tokenizer isimlerinin listesi.\n        texts (list): Özetlenecek metinlerin listesi.\n        references (list): Gerçek özetlerin listesi (texts ile aynı uzunlukta olmalı).\n        metrics_df (pd.DataFrame, optional): Başarı metriklerini saklayan mevcut DataFrame.\n                                             None ise yeni bir DataFrame oluşturulur.\n        device (str): Modeli çalıştırmak için kullanılacak cihaz ('cpu' veya 'cuda').\n\n    Returns:\n        pd.DataFrame: Güncellenmiş metrikler tablosu.\n    \"\"\"\n    # Eğer metrics_df None ise boş bir DataFrame oluştur\n    if metrics_df is None or not isinstance(metrics_df, pd.DataFrame):\n        metrics_df = pd.DataFrame(columns=[\"Model Name\", \"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"METEOR\", \"BERTScore\"])\n        print(\"Yeni bir metrics_df oluşturuldu.\")\n\n    # texts ve references uzunluk kontrolü\n    if len(texts) != len(references):\n        raise ValueError(\"texts ve references aynı uzunlukta olmalıdır.\")\n\n\n    # Quantization için BitsAndBytesConfig\n    quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16, bnb_4bit_quant_type=\"nf4\")\n    # for model_idx, (model_name, tokenizer_name) in enumerate(zip(models, tokenizer_names), start=3):\n    for model_name, tokenizer_name in zip(models, tokenizer_names):\n        # Model ve tokenizer'ı yükle\n        # model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n        model = AutoModelForCausalLM.from_pretrained(\n            model_name,\n            quantization_config=quantization_config,\n            device_map=\"auto\"  # GPU varsa otomatik cihaz ayarı\n        )\n        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, device_map = \"auto\")\n        tokenizer.pad_token = tokenizer.eos_token\n        print(f\"{model_name} yüklendi ve çıktılar alınıyor.\")\n\n        #google sheet oku\n        worksheet = initialize_google_sheets()\n        sheet_df = sheets_to_df(worksheet)\n        # Tahminleri oluştur\n        predictions = []\n        for row, text in enumerate(texts):\n            # # Girişleri cihaz üzerine taşı\n            # inputs = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=max_token_length).to(device)\n\n            # # Modelden çıktı al\n            # outputs = model.generate(inputs, max_length= max_token_length, num_beams=4, early_stopping=True)\n\n            # # Çıktıyı CPU'ya taşı ve decode et\n            # summary = tokenizer.decode(outputs[0].cpu(), skip_special_tokens=True)\n            # predictions.append(summary)\n\n            prediction = get_inference(model, tokenizer, text, max_token_length, model_name, device)\n            save_the_output(sheet_df, model_name, prediction, row)\n            predictions.append(prediction)\n\n            # Google Sheets'e yaz\n        load_data_to_the_sheet(worksheet, sheet_df)\n\n        # Başarı metriklerini DataFrame'e ekle\n        metrics_df = add_metrics_to_dataframe(metrics_df, model_name, references, predictions)\n        print(f\"Model '{model_name}' için başarı metrikleri kaydedildi.\")\n        # Belleği temizle\n        del model\n        del tokenizer\n        gc.collect()\n        torch.cuda.empty_cache()\n    return metrics_df\n\n\n\n\n# Modellerin listesi\nmodels = [\n    \"meta-llama/Llama-3.2-1B-Instruct\",\n    \"Muadil/Llama-3.2-1B-Instruct_sum_DPO_1k_4_1ep\",\n    \"Muadil/Llama-3.2-1B-Instruct_sum_DPO_10k_1_1ep\",\n    \"Muadil/Llama-3.2-1B-Instruct-sum-KTO-1k_4_1ep\",\n    \"Muadil/Llama-3.2-1B-Instruct-sum-KTO-1k_2_1ep\",\n    \"Muadil/Llama-3.2-1B-Instruct-sum-KTO-10k_1_1ep\",\n]\n\n# Tokenizer'ların listesi\ntokenizer_names = [\n    \"meta-llama/Llama-3.2-1B-Instruct\",\n    \"Muadil/Llama-3.2-1B-Instruct_sum_DPO_1k_4_1ep\",\n    \"Muadil/Llama-3.2-1B-Instruct_sum_DPO_10k_1_1ep\",\n    \"Muadil/Llama-3.2-1B-Instruct-sum-KTO-1k_4_1ep\",\n    \"Muadil/Llama-3.2-1B-Instruct-sum-KTO-1k_2_1ep\",\n    \"Muadil/Llama-3.2-1B-Instruct-sum-KTO-10k_1_1ep\",\n]\n# from google.colab import userdata\n# secret_value_0 = userdata.get('HF_TOKEN')\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n\nfrom huggingface_hub import login\nlogin(token= secret_value_0)\n\n\n# Başarı metriklerini saklamak için boş bir DataFrame oluştur\nmetrics_df = pd.DataFrame(columns=[\"Model Name\", \"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"METEOR\", \"BERTScore\"])\n\n# Fonksiyonu çalıştır ve metrikleri hesapla\nmetrics_df = summarize_and_save_metrics_AutoModelForSeq2SeqLM(\n    models=models,\n    tokenizer_names=tokenizer_names,\n    texts= list(df.iloc[:1000][\"prompt\"]),\n    references= list(df.iloc[:1000][\"chosen\"]),\n    metrics_df=metrics_df,\n    device=\"cuda\",  # GPU kullanımı\n)\n\n# Sonuçları görüntüle\nprint(metrics_df)\n\n\nfrom IPython.display import FileLink\n\n# Kaggle'da dosyayı Pickle dosyası olarak kaydet\nfile_name = \"output.pkl\"\nmetrics_df.to_pickle(file_name)\n\n# İndirme bağlantısını oluştur\ndisplay(FileLink(file_name))","metadata":{"id":"AUySfSY1DJ9b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics_df","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}